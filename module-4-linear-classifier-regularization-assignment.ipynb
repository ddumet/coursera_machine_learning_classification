{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with L2 regularization\n",
    "\n",
    "The goal of this second notebook is to implement your own logistic regression classifier with L2 regularization. You will do the following:\n",
    "\n",
    " * Extract features from Amazon product reviews.\n",
    " * Convert a DataFrame into a NumPy array.\n",
    " * Write a function to compute the derivative of log likelihood function with an L2 penalty with respect to a single coefficient.\n",
    " * Implement gradient ascent with an L2 penalty.\n",
    " * Empirically explore how the L2 penalty can ameliorate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "from math import sqrt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process review dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we will use the same subset of the Amazon product review dataset that we used in Module 3 assignment. The subset was chosen to contain similar numbers of positive and negative reviews, as the original dataset consisted of mostly positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"./data/amazon_baby_subset.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we did previously, we will work with a hand-curated list of important words extracted from the review data. We will also perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Compute word counts (only for the **important_words**)\n",
    "\n",
    "But first we replace NaN reviews with \" \" to avoid errors when processing texts later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products[\"review\"].fillna(\" \",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start with Step 1 which can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # str.maketrans create a translation table\n",
    "    # The translation table is built from a dictionary using a comprehension\n",
    "    # this maps every character from string.punctuation to None\n",
    "    translator = str.maketrans({key: None for key in string.punctuation})\n",
    "    return text.translate(translator)\n",
    "\n",
    "products[\"review_clean\"] = products[\"review\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we proceed with Step 2.\n",
    "For each word in **important_words**, we compute a count for the number of times the word occurs in the review. We will store this count in a separate column (one for each word). The result of this feature processing is a single column for each word in **important_words** which keeps a count of the number of times the respective word occurs in the review text.\n",
    "\n",
    "**Note:** There are several ways of doing this. In this assignment, we use the built-in count function for Python lists. Each review string is first split into individual words and the number of occurances of a given word is counted.\n",
    "\n",
    "Let's load these words from this JSON file first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data/important_words.json\", \"r\") as f:\n",
    "    important_words = json.load(f)\n",
    "important_words = [str(s) for s in important_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for word in important_words:\n",
    "    products[word] = products[\"review_clean\"].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, let us take a look at what the dataset looks like (**Note:** This may take a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "\n",
       "                                        review_clean  baby  one  great  love  \\\n",
       "0  All of my kids have cried nonstop when I tried...     0    0      1     0   \n",
       "1  We wanted to get something to keep track of ou...     0    0      0     0   \n",
       "\n",
       "   use   ...    seems  picture  completely  wish  buying  babies  won  tub  \\\n",
       "0    0   ...        0        0           0     0       0       0    0    0   \n",
       "1    0   ...        0        0           0     0       0       0    0    0   \n",
       "\n",
       "   almost  either  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "\n",
       "[2 rows x 198 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation split\n",
    "\n",
    "We split the data into a train-validation split with 80% of the data in the training set and 20% of the data in the validation set. We use `seed=2` so that everyone gets the same result.\n",
    "\n",
    "**Note:** In previous assignments, we have called this a **train-test split**. However, the portion of data that we don't train on will be used to help **select model parameters**. Thus, this portion of data should be called a **validation set**. Recall that examining performance of various potential models (i.e. models with different parameters) should be on a validation set, while evaluation of selected model should always be on a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and test sets\n",
    "Load the **training set** from file provided by the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"./data/module-4-assignment-train-idx.json\")\n",
    "train_data_index = f.readline()\n",
    "f.close()\n",
    "\n",
    "# Transform the read string into a list\n",
    "train_data_index = ast.literal_eval(train_data_index)\n",
    "\n",
    "train_data = products.loc[train_data_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the **validation set** from file provided by the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"./data/module-4-assignment-validation-idx.json\")\n",
    "validation_data_index = f.readline()\n",
    "f.close()\n",
    "\n",
    "# Transform the read string into a list\n",
    "validation_data_index = ast.literal_eval(validation_data_index)\n",
    "\n",
    "validation_data = products.loc[validation_data_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert DataFrame to NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Just like in the second assignment of the previous module, we provide you with a function that extracts columns from a DataFrame and converts them into a NumPy array. Two arrays are returned: one representing features and another representing class labels. \n",
    "\n",
    "**Note:** The feature matrix includes an additional column 'intercept' filled with 1's to take account of the intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    \n",
    "    # transform dataframe[features] into numpy array\n",
    "    feature_matrix = dataframe.as_matrix(features)\n",
    "    \n",
    "    # add feature x0 (i.e. a ones column vector)!\n",
    "    feature_matrix = np.insert(feature_matrix,0,np.ones([1,feature_matrix.shape[0]]),axis=1)\n",
    "    \n",
    "    label_array = dataframe.as_matrix(label)\n",
    "    \n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert both the training and validation sets into NumPy arrays.\n",
    "\n",
    "**Warning**: This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix_train, sentiment_train = get_numpy_data(train_data, important_words, [\"sentiment\"])\n",
    "feature_matrix_valid, sentiment_valid = get_numpy_data(validation_data, important_words, [\"sentiment\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are you running this notebook on an Amazon EC2 t2.micro instance?** (If you are using your own machine, please skip this section)\n",
    "\n",
    "It has been reported that t2.micro instances do not provide sufficient power to complete the conversion in acceptable amount of time. For interest of time, please refrain from running `get_numpy_data` function. Instead, download the [binary file](https://s3.amazonaws.com/static.dato.com/files/coursera/course-3/numpy-arrays/module-4-assignment-numpy-arrays.npz) containing the four NumPy arrays you'll need for the assignment. To load the arrays, run the following commands:\n",
    "```\n",
    "arrays = np.load('module-4-assignment-numpy-arrays.npz')\n",
    "feature_matrix_train, sentiment_train = arrays['feature_matrix_train'], arrays['sentiment_train']\n",
    "feature_matrix_valid, sentiment_valid = arrays['feature_matrix_valid'], arrays['sentiment_valid']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building on logistic regression with no L2 penalty assignment\n",
    "\n",
    "Let us now build on Module 3 assignment. Recall from lecture that the link function for logistic regression can be defined as:\n",
    "\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "\n",
    "where the feature vector $h(\\mathbf{x}_i)$ is given by the word counts of **important_words** in the review $\\mathbf{x}_i$. \n",
    "\n",
    "We will use the **same code** as in this past assignment to make probability predictions since this part is not affected by the L2 penalty.  (Only the way in which the coefficients are learned is affected by the addition of a regularization term.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    \n",
    "    scores = np.dot(feature_matrix,np.transpose(coefficients))\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    predictions = 1/(1+np.exp(-scores))\n",
    "    \n",
    "    return predictions.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding  L2 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now work on extending logistic regression with L2 regularization. As discussed in the lectures, the L2 regularization is particularly useful in preventing overfitting. In this assignment, we will explore L2 regularization in detail.\n",
    "\n",
    "Recall from lecture and the previous assignment that for logistic regression without an L2 penalty, the derivative of the log likelihood function is:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$\n",
    "\n",
    "** Adding L2 penalty to the derivative** \n",
    "\n",
    "It takes only a small modification to add a L2 penalty. All terms indicated in **red** refer to terms that were added due to an **L2 penalty**.\n",
    "\n",
    "* Recall from the lecture that the link function is still the sigmoid:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "* We add the L2 penalty term to the per-coefficient derivative of log likelihood:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
    "$$\n",
    "\n",
    "The **per-coefficient derivative for logistic regression with an L2 penalty** is as follows:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
    "$$\n",
    "and for the intercept term, we have\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_0} = \\sum_{i=1}^N h_0(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: As we did in the Regression course, we do not apply the L2 penalty on the intercept. A large intercept does not necessarily indicate overfitting because the intercept is not associated with any particular feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that computes the derivative of log likelihood with respect to a single coefficient $w_j$. Unlike its counterpart in the last assignment, the function accepts five arguments:\n",
    " * `errors` vector containing $(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w}))$ for all $i$\n",
    " * `feature` vector containing $h_j(\\mathbf{x}_i)$  for all $i$\n",
    " * `coefficient` containing the current value of coefficient $w_j$.\n",
    " * `l2_penalty` representing the L2 penalty constant $\\lambda$\n",
    " * `feature_is_constant` telling whether the $j$-th feature is constant or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative_with_L2(errors, feature, coefficient, l2_penalty, feature_is_constant): \n",
    "    \n",
    "    # When used in compute_log_likelihood_with_L2, feature is [1,n], i.e. row vector\n",
    "    # and errors is a column vector. So we need to do np.dot(feature, errors)\n",
    "    derivative = np.dot(feature, errors)\n",
    "    \n",
    "    # if feature is intercept do nothing\n",
    "    # else add the regularisation term -2*lambda*wj\n",
    "    if not feature_is_constant: \n",
    "        derivative = derivative - 2*l2_penalty*coefficient\n",
    "        \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz question:** In the code above, was the intercept term regularized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the correctness of the gradient ascent algorithm, we provide a function for computing log likelihood (which we recall from the last assignment was a topic detailed in an advanced optional video, and used here for its numerical stability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) \\color{red}{-\\lambda\\|\\mathbf{w}\\|_2^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty):\n",
    "    indicator = (sentiment==+1).reshape(-1,1)\n",
    "    scores = np.dot(feature_matrix, coefficients).reshape(-1,1)\n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores))) - l2_penalty*np.sum(coefficients[1:]**2)\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz question:** Does the term with L2 regularization increase or decrease $\\ell\\ell(\\mathbf{w})$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression function looks almost like the one in the last assignment, with a minor modification to account for the L2 penalty.  Fill in the code below to complete this modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, l2_penalty, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in range(max_iter):\n",
    "        \n",
    "        # Predict P(y_i = +1|x_i,w) using your predict_probability() function\n",
    "        predictions = predict_probability(feature_matrix,coefficients)\n",
    "        \n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "        \n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "        for j in range(len(coefficients)): # loop over each coefficient\n",
    "            is_intercept = (j == 0)\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n",
    "            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            derivative = feature_derivative_with_L2(errors, feature_matrix[:,j].reshape(1,-1),\n",
    "                                                    coefficients[j], l2_penalty, is_intercept)\n",
    "            \n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            coefficients[j] += step_size*derivative[0][0]\n",
    "        \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty)\n",
    "            print(\"iteration:\",itr,\"log likelihood of observed labels:\",lp)\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore effects of L2 regularization\n",
    "\n",
    "Now that we have written up all the pieces needed for regularized logistic regression, let's explore the benefits of using **L2 regularization** in analyzing sentiment for product reviews. **As iterations pass, the log likelihood should increase**.\n",
    "\n",
    "Below, we train models with increasing amounts of regularization, starting with no L2 penalty, which is equivalent to our previous logistic regression implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 log likelihood of observed labels: -29179.391383\n",
      "iteration: 1 log likelihood of observed labels: -29003.7125905\n",
      "iteration: 2 log likelihood of observed labels: -28834.6618729\n",
      "iteration: 3 log likelihood of observed labels: -28671.7078151\n",
      "iteration: 4 log likelihood of observed labels: -28514.430782\n",
      "iteration: 5 log likelihood of observed labels: -28362.4834466\n",
      "iteration: 6 log likelihood of observed labels: -28215.5671312\n",
      "iteration: 7 log likelihood of observed labels: -28073.4174378\n",
      "iteration: 8 log likelihood of observed labels: -27935.795364\n",
      "iteration: 9 log likelihood of observed labels: -27802.4816867\n",
      "iteration: 10 log likelihood of observed labels: -27673.2733148\n",
      "iteration: 11 log likelihood of observed labels: -27547.9808366\n",
      "iteration: 12 log likelihood of observed labels: -27426.4267998\n",
      "iteration: 13 log likelihood of observed labels: -27308.4444473\n",
      "iteration: 14 log likelihood of observed labels: -27193.8767388\n",
      "iteration: 15 log likelihood of observed labels: -27082.5755583\n",
      "iteration: 20 log likelihood of observed labels: -26570.4305994\n",
      "iteration: 30 log likelihood of observed labels: -25725.4874239\n",
      "iteration: 40 log likelihood of observed labels: -25055.5332691\n",
      "iteration: 50 log likelihood of observed labels: -24509.6359003\n",
      "iteration: 60 log likelihood of observed labels: -24054.9790608\n",
      "iteration: 70 log likelihood of observed labels: -23669.5164085\n",
      "iteration: 80 log likelihood of observed labels: -23337.8916763\n",
      "iteration: 90 log likelihood of observed labels: -23049.0706602\n",
      "iteration: 100 log likelihood of observed labels: -22794.9097492\n",
      "iteration: 200 log likelihood of observed labels: -21283.2952735\n",
      "iteration: 300 log likelihood of observed labels: -20570.9748547\n",
      "iteration: 400 log likelihood of observed labels: -20152.2146694\n",
      "iteration: 500 log likelihood of observed labels: -19876.6233341\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 0\n",
    "coefficients_0_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                     initial_coefficients=np.zeros(194),\n",
    "                                                     step_size=5e-6, l2_penalty=0, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 log likelihood of observed labels: -29179.3950818\n",
      "iteration: 1 log likelihood of observed labels: -29003.7341718\n",
      "iteration: 2 log likelihood of observed labels: -28834.7144186\n",
      "iteration: 3 log likelihood of observed labels: -28671.8034507\n",
      "iteration: 4 log likelihood of observed labels: -28514.5807796\n",
      "iteration: 5 log likelihood of observed labels: -28362.6983032\n",
      "iteration: 6 log likelihood of observed labels: -28215.8566326\n",
      "iteration: 7 log likelihood of observed labels: -28073.7907139\n",
      "iteration: 8 log likelihood of observed labels: -27936.2609376\n",
      "iteration: 9 log likelihood of observed labels: -27803.0475181\n",
      "iteration: 10 log likelihood of observed labels: -27673.9468421\n",
      "iteration: 11 log likelihood of observed labels: -27548.7690133\n",
      "iteration: 12 log likelihood of observed labels: -27427.3361296\n",
      "iteration: 13 log likelihood of observed labels: -27309.4810157\n",
      "iteration: 14 log likelihood of observed labels: -27195.0462425\n",
      "iteration: 15 log likelihood of observed labels: -27083.8833326\n",
      "iteration: 20 log likelihood of observed labels: -26572.4987439\n",
      "iteration: 30 log likelihood of observed labels: -25729.3260415\n",
      "iteration: 40 log likelihood of observed labels: -25061.342458\n",
      "iteration: 50 log likelihood of observed labels: -24517.5209198\n",
      "iteration: 60 log likelihood of observed labels: -24064.9909394\n",
      "iteration: 70 log likelihood of observed labels: -23681.6737367\n",
      "iteration: 80 log likelihood of observed labels: -23352.1929874\n",
      "iteration: 90 log likelihood of observed labels: -23065.5018017\n",
      "iteration: 100 log likelihood of observed labels: -22813.4484458\n",
      "iteration: 200 log likelihood of observed labels: -21321.1416479\n",
      "iteration: 300 log likelihood of observed labels: -20624.9863444\n",
      "iteration: 400 log likelihood of observed labels: -20219.9204884\n",
      "iteration: 500 log likelihood of observed labels: -19956.1134178\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 4\n",
    "coefficients_4_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                      initial_coefficients=np.zeros(194),\n",
    "                                                      step_size=5e-6, l2_penalty=4, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 log likelihood of observed labels: -29179.4006298\n",
      "iteration: 1 log likelihood of observed labels: -29003.7665416\n",
      "iteration: 2 log likelihood of observed labels: -28834.7932265\n",
      "iteration: 3 log likelihood of observed labels: -28671.9468753\n",
      "iteration: 4 log likelihood of observed labels: -28514.8057159\n",
      "iteration: 5 log likelihood of observed labels: -28363.0204808\n",
      "iteration: 6 log likelihood of observed labels: -28216.2907119\n",
      "iteration: 7 log likelihood of observed labels: -28074.3503689\n",
      "iteration: 8 log likelihood of observed labels: -27936.9589297\n",
      "iteration: 9 log likelihood of observed labels: -27803.8957627\n",
      "iteration: 10 log likelihood of observed labels: -27674.9564701\n",
      "iteration: 11 log likelihood of observed labels: -27549.9504271\n",
      "iteration: 12 log likelihood of observed labels: -27428.6990555\n",
      "iteration: 13 log likelihood of observed labels: -27311.0345514\n",
      "iteration: 14 log likelihood of observed labels: -27196.7989016\n",
      "iteration: 15 log likelihood of observed labels: -27085.8430853\n",
      "iteration: 20 log likelihood of observed labels: -26575.5969751\n",
      "iteration: 30 log likelihood of observed labels: -25735.0730461\n",
      "iteration: 40 log likelihood of observed labels: -25070.0344731\n",
      "iteration: 50 log likelihood of observed labels: -24529.3118803\n",
      "iteration: 60 log likelihood of observed labels: -24079.9534957\n",
      "iteration: 70 log likelihood of observed labels: -23699.8319919\n",
      "iteration: 80 log likelihood of observed labels: -23373.5410875\n",
      "iteration: 90 log likelihood of observed labels: -23090.0150005\n",
      "iteration: 100 log likelihood of observed labels: -22841.0899514\n",
      "iteration: 200 log likelihood of observed labels: -21377.2559533\n",
      "iteration: 300 log likelihood of observed labels: -20704.6399543\n",
      "iteration: 400 log likelihood of observed labels: -20319.2568531\n",
      "iteration: 500 log likelihood of observed labels: -20072.1632172\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 10\n",
    "coefficients_10_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                      initial_coefficients=np.zeros(194),\n",
    "                                                      step_size=5e-6, l2_penalty=10, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 log likelihood of observed labels: -29179.4838512\n",
      "iteration: 1 log likelihood of observed labels: -29004.2517746\n",
      "iteration: 2 log likelihood of observed labels: -28835.9738219\n",
      "iteration: 3 log likelihood of observed labels: -28674.0941008\n",
      "iteration: 4 log likelihood of observed labels: -28518.1711293\n",
      "iteration: 5 log likelihood of observed labels: -28367.8377465\n",
      "iteration: 6 log likelihood of observed labels: -28222.7770894\n",
      "iteration: 7 log likelihood of observed labels: -28082.7079939\n",
      "iteration: 8 log likelihood of observed labels: -27947.3759537\n",
      "iteration: 9 log likelihood of observed labels: -27816.5473862\n",
      "iteration: 10 log likelihood of observed labels: -27690.0058885\n",
      "iteration: 11 log likelihood of observed labels: -27567.5497013\n",
      "iteration: 12 log likelihood of observed labels: -27448.9899133\n",
      "iteration: 13 log likelihood of observed labels: -27334.1491274\n",
      "iteration: 14 log likelihood of observed labels: -27222.8604186\n",
      "iteration: 15 log likelihood of observed labels: -27114.9664823\n",
      "iteration: 20 log likelihood of observed labels: -26621.502013\n",
      "iteration: 30 log likelihood of observed labels: -25819.7280395\n",
      "iteration: 40 log likelihood of observed labels: -25197.340355\n",
      "iteration: 50 log likelihood of observed labels: -24701.036982\n",
      "iteration: 60 log likelihood of observed labels: -24296.6637858\n",
      "iteration: 70 log likelihood of observed labels: -23961.3884232\n",
      "iteration: 80 log likelihood of observed labels: -23679.3808885\n",
      "iteration: 90 log likelihood of observed labels: -23439.3182427\n",
      "iteration: 100 log likelihood of observed labels: -23232.8819202\n",
      "iteration: 200 log likelihood of observed labels: -22133.5072653\n",
      "iteration: 300 log likelihood of observed labels: -21730.0395749\n",
      "iteration: 400 log likelihood of observed labels: -21545.8757214\n",
      "iteration: 500 log likelihood of observed labels: -21451.9555139\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 1e2\n",
    "coefficients_1e2_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e2, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 log likelihood of observed labels: -29180.3160647\n",
      "iteration: 1 log likelihood of observed labels: -29009.0717611\n",
      "iteration: 2 log likelihood of observed labels: -28847.6237891\n",
      "iteration: 3 log likelihood of observed labels: -28695.144394\n",
      "iteration: 4 log likelihood of observed labels: -28550.9506074\n",
      "iteration: 5 log likelihood of observed labels: -28414.4577113\n",
      "iteration: 6 log likelihood of observed labels: -28285.1512438\n",
      "iteration: 7 log likelihood of observed labels: -28162.5697604\n",
      "iteration: 8 log likelihood of observed labels: -28046.2938774\n",
      "iteration: 9 log likelihood of observed labels: -27935.939029\n",
      "iteration: 10 log likelihood of observed labels: -27831.150455\n",
      "iteration: 11 log likelihood of observed labels: -27731.5995526\n",
      "iteration: 12 log likelihood of observed labels: -27636.9810822\n",
      "iteration: 13 log likelihood of observed labels: -27547.0109267\n",
      "iteration: 14 log likelihood of observed labels: -27461.4242229\n",
      "iteration: 15 log likelihood of observed labels: -27379.9737563\n",
      "iteration: 20 log likelihood of observed labels: -27027.1820832\n",
      "iteration: 30 log likelihood of observed labels: -26527.2273727\n",
      "iteration: 40 log likelihood of observed labels: -26206.5904877\n",
      "iteration: 50 log likelihood of observed labels: -25995.9690315\n",
      "iteration: 60 log likelihood of observed labels: -25854.9571028\n",
      "iteration: 70 log likelihood of observed labels: -25759.0810995\n",
      "iteration: 80 log likelihood of observed labels: -25693.0568801\n",
      "iteration: 90 log likelihood of observed labels: -25647.0992935\n",
      "iteration: 100 log likelihood of observed labels: -25614.8146871\n",
      "iteration: 200 log likelihood of observed labels: -25536.2099892\n",
      "iteration: 300 log likelihood of observed labels: -25532.5769122\n",
      "iteration: 400 log likelihood of observed labels: -25532.3554376\n",
      "iteration: 500 log likelihood of observed labels: -25532.3397005\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 1e3\n",
    "coefficients_1e3_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e3, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 log likelihood of observed labels: -29271.8595512\n",
      "iteration: 1 log likelihood of observed labels: -29271.7100659\n",
      "iteration: 2 log likelihood of observed labels: -29271.6573883\n",
      "iteration: 3 log likelihood of observed labels: -29271.6118992\n",
      "iteration: 4 log likelihood of observed labels: -29271.5707997\n",
      "iteration: 5 log likelihood of observed labels: -29271.533585\n",
      "iteration: 6 log likelihood of observed labels: -29271.4998844\n",
      "iteration: 7 log likelihood of observed labels: -29271.4693658\n",
      "iteration: 8 log likelihood of observed labels: -29271.4417289\n",
      "iteration: 9 log likelihood of observed labels: -29271.4167015\n",
      "iteration: 10 log likelihood of observed labels: -29271.3940372\n",
      "iteration: 11 log likelihood of observed labels: -29271.3735129\n",
      "iteration: 12 log likelihood of observed labels: -29271.3549266\n",
      "iteration: 13 log likelihood of observed labels: -29271.3380952\n",
      "iteration: 14 log likelihood of observed labels: -29271.3228531\n",
      "iteration: 15 log likelihood of observed labels: -29271.3090501\n",
      "iteration: 20 log likelihood of observed labels: -29271.2572915\n",
      "iteration: 30 log likelihood of observed labels: -29271.206572\n",
      "iteration: 40 log likelihood of observed labels: -29271.18776\n",
      "iteration: 50 log likelihood of observed labels: -29271.1807825\n",
      "iteration: 60 log likelihood of observed labels: -29271.1781945\n",
      "iteration: 70 log likelihood of observed labels: -29271.1772346\n",
      "iteration: 80 log likelihood of observed labels: -29271.1768785\n",
      "iteration: 90 log likelihood of observed labels: -29271.1767465\n",
      "iteration: 100 log likelihood of observed labels: -29271.1766975\n",
      "iteration: 200 log likelihood of observed labels: -29271.1766686\n",
      "iteration: 300 log likelihood of observed labels: -29271.1766686\n",
      "iteration: 400 log likelihood of observed labels: -29271.1766686\n",
      "iteration: 500 log likelihood of observed labels: -29271.1766686\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 1e5\n",
    "coefficients_1e5_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e5, max_iter=501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare coefficients\n",
    "\n",
    "We now compare the **coefficients** for each of the models that were trained above. We will create a table of features and learned coefficients associated with each of the different L2 penalty values.\n",
    "\n",
    "Create a DataFrame for this table. First column contains the list of important words (+ \"intercept\"). Then other columns contains coefficients values trained for different values of L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs_words = important_words.copy()\n",
    "coefs_words.insert(0,\"intercept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame(coefs_words,columns=[\"important_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = table.assign(L2_0=coefficients_0_penalty)\n",
    "table = table.assign(L2_4=coefficients_4_penalty)\n",
    "table = table.assign(L2_4=coefficients_4_penalty)\n",
    "table = table.assign(L2_10=coefficients_10_penalty)\n",
    "table = table.assign(L2_1e2=coefficients_1e2_penalty)\n",
    "table = table.assign(L2_1e3=coefficients_1e3_penalty)\n",
    "table = table.assign(L2_1e5=coefficients_1e5_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>important_words</th>\n",
       "      <th>L2_0</th>\n",
       "      <th>L2_4</th>\n",
       "      <th>L2_10</th>\n",
       "      <th>L2_1e2</th>\n",
       "      <th>L2_1e3</th>\n",
       "      <th>L2_1e5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intercept</td>\n",
       "      <td>-0.063742</td>\n",
       "      <td>-0.063143</td>\n",
       "      <td>-0.062256</td>\n",
       "      <td>-0.050438</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.011362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baby</td>\n",
       "      <td>0.074073</td>\n",
       "      <td>0.073994</td>\n",
       "      <td>0.073877</td>\n",
       "      <td>0.072360</td>\n",
       "      <td>0.059752</td>\n",
       "      <td>0.001784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>0.012753</td>\n",
       "      <td>0.012495</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>-0.008761</td>\n",
       "      <td>-0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>0.801625</td>\n",
       "      <td>0.796897</td>\n",
       "      <td>0.789935</td>\n",
       "      <td>0.701425</td>\n",
       "      <td>0.376012</td>\n",
       "      <td>0.008950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>1.058554</td>\n",
       "      <td>1.050856</td>\n",
       "      <td>1.039529</td>\n",
       "      <td>0.896644</td>\n",
       "      <td>0.418354</td>\n",
       "      <td>0.009042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  important_words      L2_0      L2_4     L2_10    L2_1e2    L2_1e3    L2_1e5\n",
       "0       intercept -0.063742 -0.063143 -0.062256 -0.050438  0.000054  0.011362\n",
       "1            baby  0.074073  0.073994  0.073877  0.072360  0.059752  0.001784\n",
       "2             one  0.012753  0.012495  0.012115  0.007247 -0.008761 -0.001827\n",
       "3           great  0.801625  0.796897  0.789935  0.701425  0.376012  0.008950\n",
       "4            love  1.058554  1.050856  1.039529  0.896644  0.418354  0.009042"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **the coefficients trained with L2 penalty 0**, find the 5 most positive words (with largest positive coefficients). Save them to **positive_words**. Similarly, find the 5 most negative words (with largest negative coefficients) and save them to **negative_words**.\n",
    "\n",
    "**Quiz Question**. Which of the following is **not** listed in either **positive_words** or **negative_words**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_words = table.sort_values([\"L2_0\"],ascending=False).iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>important_words</th>\n",
       "      <th>L2_0</th>\n",
       "      <th>L2_4</th>\n",
       "      <th>L2_10</th>\n",
       "      <th>L2_1e2</th>\n",
       "      <th>L2_1e3</th>\n",
       "      <th>L2_1e5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>1.058554</td>\n",
       "      <td>1.050856</td>\n",
       "      <td>1.039529</td>\n",
       "      <td>0.896644</td>\n",
       "      <td>0.418354</td>\n",
       "      <td>0.009042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loves</td>\n",
       "      <td>1.052484</td>\n",
       "      <td>1.043903</td>\n",
       "      <td>1.031265</td>\n",
       "      <td>0.870794</td>\n",
       "      <td>0.345870</td>\n",
       "      <td>0.006150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>easy</td>\n",
       "      <td>0.984559</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>0.967362</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.401904</td>\n",
       "      <td>0.008808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.835693</td>\n",
       "      <td>0.828555</td>\n",
       "      <td>0.818038</td>\n",
       "      <td>0.684143</td>\n",
       "      <td>0.250614</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>0.801625</td>\n",
       "      <td>0.796897</td>\n",
       "      <td>0.789935</td>\n",
       "      <td>0.701425</td>\n",
       "      <td>0.376012</td>\n",
       "      <td>0.008950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   important_words      L2_0      L2_4     L2_10    L2_1e2    L2_1e3    L2_1e5\n",
       "4             love  1.058554  1.050856  1.039529  0.896644  0.418354  0.009042\n",
       "23           loves  1.052484  1.043903  1.031265  0.870794  0.345870  0.006150\n",
       "8             easy  0.984559  0.977600  0.967362  0.838245  0.401904  0.008808\n",
       "34         perfect  0.835693  0.828555  0.818038  0.684143  0.250614  0.003989\n",
       "3            great  0.801625  0.796897  0.789935  0.701425  0.376012  0.008950"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_words = table.sort_values([\"L2_0\"],ascending=True).iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>important_words</th>\n",
       "      <th>L2_0</th>\n",
       "      <th>L2_4</th>\n",
       "      <th>L2_10</th>\n",
       "      <th>L2_1e2</th>\n",
       "      <th>L2_1e3</th>\n",
       "      <th>L2_1e5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>-0.955437</td>\n",
       "      <td>-0.946980</td>\n",
       "      <td>-0.934518</td>\n",
       "      <td>-0.775625</td>\n",
       "      <td>-0.266095</td>\n",
       "      <td>-0.004013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>money</td>\n",
       "      <td>-0.768793</td>\n",
       "      <td>-0.762734</td>\n",
       "      <td>-0.753818</td>\n",
       "      <td>-0.641406</td>\n",
       "      <td>-0.275883</td>\n",
       "      <td>-0.005487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>return</td>\n",
       "      <td>-0.742085</td>\n",
       "      <td>-0.735502</td>\n",
       "      <td>-0.725807</td>\n",
       "      <td>-0.602646</td>\n",
       "      <td>-0.215199</td>\n",
       "      <td>-0.003730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>waste</td>\n",
       "      <td>-0.617809</td>\n",
       "      <td>-0.612475</td>\n",
       "      <td>-0.604620</td>\n",
       "      <td>-0.505189</td>\n",
       "      <td>-0.190631</td>\n",
       "      <td>-0.003345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>returned</td>\n",
       "      <td>-0.572707</td>\n",
       "      <td>-0.567518</td>\n",
       "      <td>-0.559870</td>\n",
       "      <td>-0.462056</td>\n",
       "      <td>-0.150021</td>\n",
       "      <td>-0.002225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    important_words      L2_0      L2_4     L2_10    L2_1e2    L2_1e3  \\\n",
       "106    disappointed -0.955437 -0.946980 -0.934518 -0.775625 -0.266095   \n",
       "97            money -0.768793 -0.762734 -0.753818 -0.641406 -0.275883   \n",
       "114          return -0.742085 -0.735502 -0.725807 -0.602646 -0.215199   \n",
       "113           waste -0.617809 -0.612475 -0.604620 -0.505189 -0.190631   \n",
       "169        returned -0.572707 -0.567518 -0.559870 -0.462056 -0.150021   \n",
       "\n",
       "       L2_1e5  \n",
       "106 -0.004013  \n",
       "97  -0.005487  \n",
       "114 -0.003730  \n",
       "113 -0.003345  \n",
       "169 -0.002225  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us observe the effect of increasing L2 penalty on the 10 words just selected. We provide you with a utility function to  plot the coefficient path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "def make_coefficient_plot(positive_words, negative_words, l2_penalty_list):\n",
    "    cmap_positive = plt.get_cmap('Reds')\n",
    "    cmap_negative = plt.get_cmap('Blues')\n",
    "    \n",
    "    xx = l2_penalty_list\n",
    "    plt.plot(xx, [0.]*len(xx), '--', lw=1, color='k')\n",
    "    \n",
    "    table_positive_words = positive_words.drop([\"important_words\"], axis=1, inplace=False)\n",
    "    table_negative_words = negative_words.drop([\"important_words\"], axis=1, inplace=False)\n",
    "    \n",
    "    label_positive_words = positive_words[\"important_words\"]\n",
    "    label_negative_words = negative_words[\"important_words\"]\n",
    "    \n",
    "    for i in range(len(table_positive_words)):\n",
    "        color = cmap_positive(0.8*((i+1)/(len(table_positive_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_positive_words[i:i+1].as_matrix().flatten(),\n",
    "                 '-', label=label_positive_words.iloc[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    for i in range(len(table_negative_words)):\n",
    "        color = cmap_negative(0.8*((i+1)/(len(table_negative_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_negative_words[i:i+1].as_matrix().flatten(),\n",
    "                 '-', label=label_negative_words.iloc[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    plt.legend(loc='best', ncol=3, prop={'size':16}, columnspacing=0.5)\n",
    "    plt.axis([1, 1e5, -1, 2])\n",
    "    plt.title('Coefficient path')\n",
    "    plt.xlabel('L2 penalty ($\\lambda$)')\n",
    "    plt.ylabel('Coefficient value')\n",
    "    plt.xscale('log')\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to generate the plot. Use the plot to answer the following quiz question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAGYCAYAAACphJGEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n78ADGb+DJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ae526d7898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_coefficient_plot(positive_words, negative_words, l2_penalty_list=[0, 4, 10, 1e2, 1e3, 1e5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: (True/False) All coefficients consistently get smaller in size as the L2 penalty is increased.\n",
    "\n",
    "**Quiz Question**: (True/False) The relative order of coefficients is preserved as the L2 penalty is increased. (For example, if the coefficient for 'cat' was more positive than that for 'dog', this remains true as the L2 penalty increases.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy\n",
    "\n",
    "Now, let us compute the accuracy of the classifier model. Recall that the accuracy is given by\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$\n",
    "\n",
    "\n",
    "Recall from lecture that that the class prediction is calculated using\n",
    "$$\n",
    "\\hat{y}_i = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & h(\\mathbf{x}_i)^T\\mathbf{w} > 0 \\\\\n",
    "      -1 & h(\\mathbf{x}_i)^T\\mathbf{w} \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "**Note**: It is important to know that the model prediction code doesn't change even with the addition of an L2 penalty. The only thing that changes is the estimated coefficients used in this prediction.\n",
    "\n",
    "Based on the above, we will use the same code that was used in Module 3 assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(feature_matrix, sentiment, coefficients):\n",
    "    scores = np.dot(feature_matrix, coefficients.reshape(-1,1))\n",
    "    \n",
    "    predictions = scores.copy()\n",
    "    predictions[predictions>0] = 1\n",
    "    predictions[predictions<=0] = -1\n",
    "    \n",
    "    num_correct = (predictions == sentiment).sum()\n",
    "    accuracy = num_correct / len(feature_matrix)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we compare the accuracy on the **training data** and **validation data** for all the models that were trained in this assignment.  We first calculate the accuracy values and then build a simple report summarizing the performance for the various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_accuracy = {}\n",
    "train_accuracy[0]   = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_0_penalty)\n",
    "train_accuracy[4]   = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_4_penalty)\n",
    "train_accuracy[10]  = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_10_penalty)\n",
    "train_accuracy[1e2] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e2_penalty)\n",
    "train_accuracy[1e3] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e3_penalty)\n",
    "train_accuracy[1e5] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e5_penalty)\n",
    "\n",
    "validation_accuracy = {}\n",
    "validation_accuracy[0]   = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_0_penalty)\n",
    "validation_accuracy[4]   = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_4_penalty)\n",
    "validation_accuracy[10]  = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_10_penalty)\n",
    "validation_accuracy[1e2] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e2_penalty)\n",
    "validation_accuracy[1e3] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e3_penalty)\n",
    "validation_accuracy[1e5] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e5_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 penalty = 0\n",
      "train accuracy = 0.785156157787 validation_accuracy = 0.78143964149\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 4\n",
      "train accuracy = 0.785108944548 validation_accuracy = 0.781533003454\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 10\n",
      "train accuracy = 0.784990911452 validation_accuracy = 0.781719727383\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 100.0\n",
      "train accuracy = 0.783975826822 validation_accuracy = 0.781066193633\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 1000.0\n",
      "train accuracy = 0.775855149784 validation_accuracy = 0.771356549342\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 100000.0\n",
      "train accuracy = 0.680366374731 validation_accuracy = 0.667818130893\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Build a simple report\n",
    "for key in sorted(validation_accuracy.keys()):\n",
    "    print(\"L2 penalty =\",key)\n",
    "    print(\"train accuracy =\",train_accuracy[key],\"validation_accuracy =\",validation_accuracy[key])\n",
    "    print(\"--------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Quiz question**: Which model (L2 = 0, 4, 10, 100, 1e3, 1e5) has the **highest** accuracy on the **training** data?\n",
    "* **Quiz question**: Which model (L2 = 0, 4, 10, 100, 1e3, 1e5) has the **highest** accuracy on the **validation** data?\n",
    "* **Quiz question**: Does the **highest** accuracy on the **training** data imply that the model is the best one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
